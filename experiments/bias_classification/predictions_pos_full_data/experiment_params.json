{
  "intermediary_task":{
    "model_path":"../../../tasks/bias_classification/lib/debiaser/final_model/joint/model_7.ckpt",
    "general_model_params":{
      "num_attention_heads":12,
      "num_layers":12,
      "attention_head_size": 768,
      "hidden_size": 512,
      "emb_dim":768,
      "dropout":0.2,
      "max_seq_len":80
    },
    "attention":{
      "layers":[0,1,2,3,4,5,6,7,8,9,10,11],
      "num_attention_heads":1,
      "attention_head_size":768,
      "attention_extraction_batch_size":1
    },
    "task_specific_params":{
      "num_categories":43,
      "num_tok_labels":3,
      "working_dir":"../../../tasks/bias_classification/results",
      "bert_model":"bert-base-uncased",
      "target_data":"../../../tasks/bias_classification/data/train_dev.tsv",
      "target_labels":"../../../tasks/bias_classification/data/bias_labels_train_dev.tsv",
      "full_data":"../../../tasks/bias_classification/data/final/biased.word.train",
      "lexicon_dir":"../../../tasks/bias_classification/data/lexicons",
      "test_batch_size":1,
      "transformer_layers":1,
      "debias_weight":1.3,
      "pointer_generator":true,
      "bert_encoder":true,
      "bert_full_embeddings":true,
      "activation_hidden":true,
      "freeze_tagger":true,
      "pre_enrich":true,
      "token_softmax":true,
      "drop_words":false,
      "category_input":false,
      "noise_prob":0.25,
      "shuf_dist":3,
      "keep_bigrams":false,
      "combiner_layers":1,
      "small_waist":false,
      "concat_categories":false,
      "category_emb":false,
      "add_category_emb":false,
      "lexicon_feature_bits":1,
      "transformer_decoder":false,
      "bert_word_embeddings":false,
      "freeze_embeddings":false,
      "no_tok_enrich":false,
      "sigmoid_bridge":false,
      "coverage":false,
      "zero_threshold":-10000.0,
      "sequence_softmax":false
    }
  },
  "final_task":{
    "model":"log_reg",
    "data_split":{
      "train_split":0.7,
      "eval_split": 0.3,
      "test_split": 0
    },
    "training_params":{
      "num_epochs":200,
      "batch_size":32,
      "lr":1e-2
    }
  }
}
