{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snorkel for Bias\n",
    "Label model for weakly-supervised bias classification problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "os.chdir(\"/Users/sabrieyuboglu/Documents/sabri/school/cs_224u/attention_analysis\")\n",
    "\n",
    "import torch\n",
    "from scipy import sparse\n",
    "from metal.label_model import LabelModel  \n",
    "\n",
    "from src.utils import *\n",
    "from tasks.bias_classification.lib.tagging.features import Featurizer\n",
    "\n",
    "os.chdir(\"/Users/sabrieyuboglu/Documents/sabri/school/cs_224u/attention_analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Weak Labels\n",
    "Load the weak labels for the entire bias classiciation dataset. \n",
    "\n",
    "Output: an [n,m] scipy.sparse label matrix of noisy labels where n= # data points, m = # labeling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load labeler outputs\n",
    "pos_dataset = pickle.load(open('tasks/bias_classification/data/labels/pos_weak_labels.pkl', 'rb'))\n",
    "word2vec_dataset = pickle.load(open('tasks/bias_classification/data/labels/word2vec_weak_labels.pkl', 'rb'))\n",
    "marta_dataset = pickle.load(open('tasks/bias_classification/data/labels/marta_weak_labels.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [(pos_dataset, \"pos_weak_labels\"), \n",
    "       (word2vec_dataset, \"word2vec_weak_labels\"),\n",
    "       (marta_dataset, \"marta_weak_labels\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = torch.max(marta_dataset.data[\"index\"]) + 1\n",
    "m = len(lfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lf matrix\n",
    "lf_matrix = np.full((n, m), fill_value=-1)\n",
    "lf_to_idx = {}\n",
    "for lf_idx, (labeler, key) in enumerate(lfs):\n",
    "    lf_to_idx[key] = lf_idx\n",
    "    for entry in labeler:\n",
    "        entry_idx = entry[\"index\"]\n",
    "        label = entry[key]\n",
    "        lf_matrix[entry_idx, lf_idx] = label + 1\n",
    "        \n",
    "# remove incomplete rows\n",
    "\n",
    "idx_to_id = list(set(range(lf_matrix.shape[0])) - set(np.where(lf_matrix == -1)[0]))\n",
    "lf_matrix = lf_matrix[idx_to_index, :]\n",
    "lf_matrix = sparse.csr_matrix(lf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.401135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.401135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.401135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Polarity  Coverage  Overlaps  Conflicts\n",
       "0   [1, 2]       1.0       1.0   0.401135\n",
       "1   [1, 2]       1.0       1.0   0.401135\n",
       "2   [1, 2]       1.0       1.0   0.401135"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analyze labeling functions\n",
    "from metal.analysis import lf_summary\n",
    "\n",
    "lf_summary(lf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Label Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metal.analysis import lf_summary\n",
    "\n",
    "label_model = LabelModel(k=2, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing O...\n",
      "Estimating \\mu...\n",
      "[1 epo]: TRAIN:[loss=1.401]\n",
      "[2 epo]: TRAIN:[loss=1.343]\n",
      "[3 epo]: TRAIN:[loss=1.234]\n",
      "[4 epo]: TRAIN:[loss=1.084]\n",
      "[5 epo]: TRAIN:[loss=0.903]\n",
      "[6 epo]: TRAIN:[loss=0.704]\n",
      "[7 epo]: TRAIN:[loss=0.504]\n",
      "[8 epo]: TRAIN:[loss=0.321]\n",
      "[9 epo]: TRAIN:[loss=0.176]\n",
      "[10 epo]: TRAIN:[loss=0.083]\n",
      "[11 epo]: TRAIN:[loss=0.049]\n",
      "[12 epo]: TRAIN:[loss=0.072]\n",
      "[13 epo]: TRAIN:[loss=0.134]\n",
      "[14 epo]: TRAIN:[loss=0.210]\n",
      "[15 epo]: TRAIN:[loss=0.273]\n",
      "[16 epo]: TRAIN:[loss=0.303]\n",
      "[17 epo]: TRAIN:[loss=0.293]\n",
      "[18 epo]: TRAIN:[loss=0.249]\n",
      "[19 epo]: TRAIN:[loss=0.186]\n",
      "[20 epo]: TRAIN:[loss=0.121]\n",
      "[21 epo]: TRAIN:[loss=0.068]\n",
      "[22 epo]: TRAIN:[loss=0.034]\n",
      "[23 epo]: TRAIN:[loss=0.020]\n",
      "[24 epo]: TRAIN:[loss=0.022]\n",
      "[25 epo]: TRAIN:[loss=0.035]\n",
      "[26 epo]: TRAIN:[loss=0.051]\n",
      "[27 epo]: TRAIN:[loss=0.067]\n",
      "[28 epo]: TRAIN:[loss=0.077]\n",
      "[29 epo]: TRAIN:[loss=0.082]\n",
      "[30 epo]: TRAIN:[loss=0.079]\n",
      "[31 epo]: TRAIN:[loss=0.071]\n",
      "[32 epo]: TRAIN:[loss=0.058]\n",
      "[33 epo]: TRAIN:[loss=0.044]\n",
      "[34 epo]: TRAIN:[loss=0.030]\n",
      "[35 epo]: TRAIN:[loss=0.019]\n",
      "[36 epo]: TRAIN:[loss=0.012]\n",
      "[37 epo]: TRAIN:[loss=0.008]\n",
      "[38 epo]: TRAIN:[loss=0.009]\n",
      "[39 epo]: TRAIN:[loss=0.012]\n",
      "[40 epo]: TRAIN:[loss=0.016]\n",
      "[41 epo]: TRAIN:[loss=0.020]\n",
      "[42 epo]: TRAIN:[loss=0.022]\n",
      "[43 epo]: TRAIN:[loss=0.022]\n",
      "[44 epo]: TRAIN:[loss=0.021]\n",
      "[45 epo]: TRAIN:[loss=0.018]\n",
      "[46 epo]: TRAIN:[loss=0.014]\n",
      "[47 epo]: TRAIN:[loss=0.010]\n",
      "[48 epo]: TRAIN:[loss=0.006]\n",
      "[49 epo]: TRAIN:[loss=0.004]\n",
      "[50 epo]: TRAIN:[loss=0.003]\n",
      "[51 epo]: TRAIN:[loss=0.003]\n",
      "[52 epo]: TRAIN:[loss=0.004]\n",
      "[53 epo]: TRAIN:[loss=0.005]\n",
      "[54 epo]: TRAIN:[loss=0.005]\n",
      "[55 epo]: TRAIN:[loss=0.006]\n",
      "[56 epo]: TRAIN:[loss=0.006]\n",
      "[57 epo]: TRAIN:[loss=0.006]\n",
      "[58 epo]: TRAIN:[loss=0.005]\n",
      "[59 epo]: TRAIN:[loss=0.004]\n",
      "[60 epo]: TRAIN:[loss=0.003]\n",
      "[61 epo]: TRAIN:[loss=0.003]\n",
      "[62 epo]: TRAIN:[loss=0.002]\n",
      "[63 epo]: TRAIN:[loss=0.001]\n",
      "[64 epo]: TRAIN:[loss=0.001]\n",
      "[65 epo]: TRAIN:[loss=0.001]\n",
      "[66 epo]: TRAIN:[loss=0.001]\n",
      "[67 epo]: TRAIN:[loss=0.002]\n",
      "[68 epo]: TRAIN:[loss=0.002]\n",
      "[69 epo]: TRAIN:[loss=0.002]\n",
      "[70 epo]: TRAIN:[loss=0.002]\n",
      "[71 epo]: TRAIN:[loss=0.002]\n",
      "[72 epo]: TRAIN:[loss=0.002]\n",
      "[73 epo]: TRAIN:[loss=0.001]\n",
      "[74 epo]: TRAIN:[loss=0.001]\n",
      "[75 epo]: TRAIN:[loss=0.001]\n",
      "[76 epo]: TRAIN:[loss=0.001]\n",
      "[77 epo]: TRAIN:[loss=0.001]\n",
      "[78 epo]: TRAIN:[loss=0.001]\n",
      "[79 epo]: TRAIN:[loss=0.001]\n",
      "[80 epo]: TRAIN:[loss=0.001]\n",
      "[81 epo]: TRAIN:[loss=0.001]\n",
      "[82 epo]: TRAIN:[loss=0.001]\n",
      "[83 epo]: TRAIN:[loss=0.001]\n",
      "[84 epo]: TRAIN:[loss=0.001]\n",
      "[85 epo]: TRAIN:[loss=0.001]\n",
      "[86 epo]: TRAIN:[loss=0.000]\n",
      "[87 epo]: TRAIN:[loss=0.000]\n",
      "[88 epo]: TRAIN:[loss=0.000]\n",
      "[89 epo]: TRAIN:[loss=0.000]\n",
      "[90 epo]: TRAIN:[loss=0.000]\n",
      "[91 epo]: TRAIN:[loss=0.000]\n",
      "[92 epo]: TRAIN:[loss=0.000]\n",
      "[93 epo]: TRAIN:[loss=0.000]\n",
      "[94 epo]: TRAIN:[loss=0.000]\n",
      "[95 epo]: TRAIN:[loss=0.000]\n",
      "[96 epo]: TRAIN:[loss=0.000]\n",
      "[97 epo]: TRAIN:[loss=0.000]\n",
      "[98 epo]: TRAIN:[loss=0.000]\n",
      "[99 epo]: TRAIN:[loss=0.000]\n",
      "[100 epo]: TRAIN:[loss=0.000]\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "label_model.train_model(lf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = label_model.predict(lf_matrix) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_idx_to_id = []\n",
    "for idx, entry in enumerate(pos_dataset):\n",
    "    dataset_idx_to_id.append(entry[\"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_idx_to_id == idx_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dataset.add_data(labels, key_name=\"bias_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pos_dataset, open(\"tasks/bias_classification/data/labels/bias_labels.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
