{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append(\"../../../../..\")\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from src.experiment import AttentionExperiment, ClassificationExperiment\n",
    "from src.dataset import ExperimentDataset\n",
    "from src.params import Params\n",
    "from src.utils.attention_utils import reduce_attention_dist\n",
    "from src.utils.classification_utils import run_bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Params.read_params(\"gru-params.json\")\n",
    "print(\"layers = {}\".format(params.intermediary_task[\"attention\"][\"layers\"]))\n",
    "print(\"reducer = {}\".format(params.intermediary_task[\"attention\"][\"reducer\"]))\n",
    "print(\"n_components = {}\".format(params.intermediary_task[\"attention\"][\"n_components\"]))\n",
    "print(\"dropout = {}\".format(params.final_task[\"dropout\"]))\n",
    "print(\"hidden_dim = {}\".format(params.final_task[\"hidden_dim\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = ExperimentDataset.init_dataset(params.dataset)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attention_dataloader = dataset.return_dataloader() \n",
    "attention_experiment = AttentionExperiment.initialize_attention_experiment(\n",
    "    params.intermediary_task, \n",
    "    params.dataset,\n",
    "    from_pretrained=True,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_scores = attention_experiment.extract_attention_scores(attention_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [int(d[\"pre_lens\"].numpy()) for d in dataset]\n",
    "reduced_attention = reduce_attention_dist(attention_scores, params.intermediary_task[\"attention\"], lengths)\n",
    "dataset.add_data(reduced_attention, \"attention_dist\")\n",
    "print(\"reduced_attention.shape = {}\".format(reduced_attention.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is where the classification experiment starts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a classification experiment that contains useful methods for classifying bias based on the attention distributions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_experiment = ClassificationExperiment.init_cls_experiment(\n",
    "    params.final_task, \n",
    "    params.intermediary_task[\"attention\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = run_bootstrapping(\n",
    "    classification_experiment, \n",
    "    dataset, \n",
    "    params.final_task, \n",
    "    num_bootstrap_iters=20,\n",
    "    input_key=\"attention_dist\", \n",
    "    label_key=\"bias_label\",\n",
    "    shuffle_data=True,\n",
    "    seed=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_attention_dataloader = dataset.return_dataloader() \n",
    "batch_attention_scores = classification_experiment.extract_attention_scores(\n",
    "    gru_attention_dataloader,\n",
    "    input_key=\"attention_dist\", \n",
    "    label_key=\"bias_label\",\n",
    "    seq_len_key=\"pre_lens\",\n",
    "    attention_mask_key=\"masks\"\n",
    ")\n",
    "attention_scores = np.array([score.numpy() for batch in batch_attention_scores for score in batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "\n",
    "labels = dataset.get_val('bias_label')\n",
    "labels_0_indices = (labels == 0).nonzero()\n",
    "labels_1_indices = labels.nonzero()\n",
    "\n",
    "attention_scores_0 = attention_scores[labels_0_indices].squeeze() # epistemological \n",
    "attention_scores_1 = attention_scores[labels_1_indices].squeeze() # framing\n",
    "\n",
    "entropy_0 = entropy(attention_scores_0.T)\n",
    "entropy_1 = entropy(attention_scores_1.T)\n",
    "\n",
    "avg_entropy_0 = np.mean(entropy_0)\n",
    "avg_entropy_1 = np.mean(entropy_1)\n",
    "\n",
    "print(\"Entropy Epistemological: {} \\t Entropy Framing {}\".format(avg_entropy_0, avg_entropy_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
