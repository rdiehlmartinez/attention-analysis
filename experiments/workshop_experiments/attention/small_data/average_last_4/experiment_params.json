{
  "intermediary_task":{
    "model_path":"../../../../../lib/debiaser/final_model/joint/model_7.ckpt",
    "general_model_params":{
      "num_attention_heads":12,
      "num_layers":12,
      "attention_head_size":768,
      "hidden_size":512,
      "emb_dim":768,
      "dropout":0.2,
      "max_seq_len":80
    },
    "attention":{
      "layers":[8,9,10,11],
      "num_attention_heads":1,
      "attention_head_size":768,
      "attention_extraction_batch_size":1 
    },
    "task_specific_params":{
      "num_categories":43,
      "num_tok_labels":3,
      "working_dir":".",
      "bert_model":"bert-base-uncased",
      "lexicon_dir":"../../../../../data/lexicons",
      "test_batch_size":1,
      "transformer_layers":1,
      "debias_weight":1.3,
      "pointer_generator":true,
      "bert_encoder":true,
      "bert_full_embeddings":true,
      "activation_hidden":true,
      "freeze_tagger":true,
      "pre_enrich":true,
      "token_softmax":true,
      "drop_words":null,
      "category_input":false,
      "noise_prob":0.25,
      "shuf_dist":3,
      "keep_bigrams":false,
      "combiner_layers":1,
      "small_waist":false,
      "concat_categories":false,
      "category_emb":false,
      "add_category_emb":false,
      "lexicon_feature_bits":1,
      "transformer_decoder":false,
      "bert_word_embeddings":false,
      "freeze_embeddings":false,
      "no_tok_enrich":false,
      "sigmoid_bridge":false,
      "coverage":false,
      "zero_threshold":-10000.0,
      "sequence_softmax":false
    }
  },
  "final_task":{
    "labeled_data":"../../../../../data/small_bias.tsv",
    "model":"gru",
    "input_dim":80, 
    "hidden_dim":50,
    "output_dim":1,
    "n_layers":2,
    "dropout":0.2,
    "data_split":{
      "train_split":0.8,
      "eval_split":0.2
    },
    "training_params":{
      "optimizer":"adam",
      "loss":"bce_with_logits",
      "num_epochs":200,
      "batch_size":32,
      "lr":1e-3
    }
  }
}
